** UNDER CONSTRUCTION (2024.2.17) **

## Conctructing Prediction Functions

This folder contains the codes used to construct the prediction functions between the given desctiptor file of the whole data set (`SINGLE_xxx`) or the two subsets (`SEP_xxx`).

In both cases, we conduct the experiment in two steps, namely:
- the preliminary experiment (`xxx_pre`) to specify the hyperparameters, and
- the evaluation experiment (`xxx_eval`) to evaluate the learning performance by 10 times 5-cross validation, and construct the prediction function files that will be used later in the stage of solving inverse problem ([Module 3](HPS/Module_3)).

Usage:

For learning using the whole data set (`SINGLE_xxx`):

Preliminary experiment:

```
python SINGLE_pre.py DATASET_desc_norm.csv DATASET_values.txt -learning_method
```

Here:
- DATASET_desc_norm.csv(DATASET_hK_desc_norm.csv): the linear(quadratic) descriptor files generated in [Module 1](/HPS/Module_1) of the whole given data set;
- DATASET_values.txt: the file containing observed value information of the data set, and;
- -learning_method: the learning method (`-l` for LLR, `-ann` for ANN, `-alr` for ALR, and `-rbsp` for RLR).

Evaluation experiment:

```
python SINGLE_eval.py DATASET_desc_norm.csv DATASET_values.txt -learning_method (...)
```

Basically the inputs should be the same as the ones used for the preliminary experiment, except:
- -learning_method (...): the learning method **AND** the correspoding parameters obtained in the preliminary experiment (see the example below).

A sample usage:

For preliminary experiment:

```
python SINGLE_pre.py ./sample_instance/At_large_var0_desc_norm.csv ./sample_instance/At_large_norm_values.txt -l
```

The output will be like:

```
At_large_var0	448	254	254	0	Lasso	0.5797154425805995	0.408987110958712	167.51508474349976		-l 0.00073
```

And for evaluation experiment:

```
python SINGLE_eval.py ./sample_instance/At_large_var0_desc_norm.csv ./sample_instance/At_large_norm_values.txt -l 0.00073
```

Here `-l 0.00073` is the selected parameter obtained from the preliminary experiment.

When the code finishes normally, it will output the information about the learning performance like:

| Data set | \#instance | \#descritpors | \#linear descriptors | \#quadratic descriptors | learning method | median of train R<sup>2</sup> | min of train R<sup>2</sup> | max of train R<sup>2</sup> | median of test R<sup>2</sup> | min of test R<sup>2</sup> | max of test R<sup>2</sup> | running time(sec) |
| --- | --- |
| At_large_var0 | 448 | 254 | 254 | 0 | Lasso | 0.5773279046164392 | 0.5366019574027185 | 0.6211274634517285 | 0.3911713431555095 | 0.038081164737786555 | 0.521242342190777 | 0.16965603828430176 |

For learning using the two subsets generated by [Splitting Data Sets via Hyperplanes](HPS/Module_2/Splitting_Data_Sets_via_Hyperplane):

Preliminary experiment:

```
python
```

Here:
- C1_desc_norm.csv: the linear/quadratic descriptor files of the subset 'C1';
- C1_values.txt: the file containing observed value information of the subset 'C1';
- C2_desc_norm.csv: the linear/quadratic descriptor files of the subset 'C2';
- C2_values.txt: the file containing observed value information of the subset 'C2';
- -learning_method_for_C1:
- -learning_method_for_C2:

The output will be

Evaluation experiment:

```
python
```

Here:

The output will be






